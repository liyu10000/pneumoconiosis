{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This is a 14-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../CHESTXRAY/Data_Entry_2017.csv')\n",
    "df = df.sample(frac=1)  # shuffle dataframe\n",
    "image_dir = '../../images'\n",
    "image_path = {f:os.path.join(image_dir,f) for f in os.listdir(image_dir)}\n",
    "print(\"Scans found: {}, total headers: {}\".format(len(image_path), df.shape[0]))\n",
    "df['path'] = df['Image Index'].map(image_path.get)  # add path column\n",
    "# note: df['Patient Age'] has value larger than 100\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['Finding Labels'].value_counts()[:15]\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 6))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "print(len(all_labels), all_labels)\n",
    "for c_label in all_labels:\n",
    "    df[c_label] = df['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0)\n",
    "df.to_csv(\"Data_Entry_2017_shuffled.csv\")  # save shuffled data, for convenience of later prediction\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion',\n",
    "           'Emphysema','Fibrosis','Hernia','Infiltration','Mass','Nodule',\n",
    "           'Pleural_Thickening','Pneumonia','Pneumothorax']\n",
    "nb_records, nb_classes = df.shape[0], len(classes)\n",
    "print(nb_records, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:int(nb_records*0.7)]\n",
    "valid_df = df.iloc[int(nb_records*0.7):int(nb_records*0.9)]\n",
    "test_df = df.iloc[int(nb_records*0.9):]\n",
    "print(train_df.shape, valid_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ModelFactory\n",
    "\n",
    "image_shape = (224, 224, 3)  # input image shape\n",
    "model = ModelFactory(nb_classes, image_shape).densenet121()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_weights import get_class_weights\n",
    "class_weights = get_class_weights(df, classes)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "weight_path=\"weights_{epoch:03d}_{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='acc', verbose=1, \n",
    "                             save_best_only=False, mode='max', save_weights_only=True)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "reduceLR = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, verbose=1, \n",
    "                             mode=\"min\", cooldown=5, min_lr=1e-8)\n",
    "callbacks = [checkpoint, early, reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import DataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = DataGenerator(train_df, path_key=\"path\", classes_key=classes, batch_size=batch_size)\n",
    "valid_generator = DataGenerator(valid_df, path_key=\"path\", classes_key=classes, batch_size=batch_size, shuffle=False)\n",
    "print(len(train_generator), len(valid_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, \n",
    "                              epochs=nb_epoch, \n",
    "                              validation_data=valid_generator, \n",
    "                              callbacks=callbacks, \n",
    "                              class_weight=class_weights, \n",
    "                              verbose=1,\n",
    "                              workers=6, \n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# dump history\n",
    "with open(\"history.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"history\": history.history,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_20181018-1019/weights_034_0.3282.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(test_df, path_key=\"path\", classes_key=classes, batch_size=batch_size, shuffle=False)\n",
    "print(len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator, verbose=1)\n",
    "print(type(y_pred), len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df[classes].values\n",
    "print(type(y_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classification\n",
    "\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "thres = 0.5  # threshold to determine if was a valid prediction\n",
    "for r_test, r_pred in zip(y_test, y_pred):\n",
    "    tp += 1 if r_test.sum() > 0 and r_pred.max() > thres else 0  # predicted desease\n",
    "    tn += 1 if r_test.sum() == 0 and r_pred.max() <= thres else 0\n",
    "    fp += 1 if r_test.sum() == 0 and r_pred.max() > thres else 0\n",
    "    fn += 1 if r_test.sum() > 0 and r_pred.max() <= thres else 0\n",
    "print(\"tp = {}, tn = {}, fp = {}, fn = {}\\n\".format(tp, tn, fp, fn))\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
